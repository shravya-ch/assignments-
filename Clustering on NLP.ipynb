{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment2_11017.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "7sZ5bsRQg-V9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd \n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn import metrics\n",
        "import nltk"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9e2DkBshhGii",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = fetch_20newsgroups(subset='all',shuffle=True, random_state=42,remove=('headers', 'footers', 'quotes'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0O3HnFChRNk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset.data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQ6eCWiOhplb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.DataFrame(data = dataset.data,columns=['text'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_YJYBjNh77q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.shape\n",
        "df.head(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FoRroqxtjoVu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stopwords= set(['br', 'the', 'i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\",\\\n",
        "            \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', \\\n",
        "            'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their',\\\n",
        "            'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', \\\n",
        "            'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', \\\n",
        "            'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', \\\n",
        "            'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after',\\\n",
        "            'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further',\\\n",
        "            'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\\\n",
        "            'most', 'other', 'some', 'such', 'only', 'own', 'same', 'so', 'than', 'too', 'very', \\\n",
        "            's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', \\\n",
        "            've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn',\\\n",
        "            \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn',\\\n",
        "            \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", \\\n",
        "            'won', \"won't\", 'wouldn', \"wouldn't\"])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySPMLVNSjqgs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def decontracted(phrase):\n",
        "    # specific\n",
        "    phrase = re.sub(r\"won't\", \"will not\", phrase)\n",
        "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
        "    # general\n",
        "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
        "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
        "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
        "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
        "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
        "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
        "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
        "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
        "    return phrase\n",
        "\n",
        "preprocessed_reviews = []\n",
        "for sentence in (df['text']):\n",
        "    sentence = re.sub(r\"http\\S+\", \"\", sentence)\n",
        "    sentence = BeautifulSoup(sentence, 'lxml').get_text()\n",
        "    sentence = decontracted(sentence)\n",
        "    sentence = re.sub(\"\\S*\\d\\S*\", \"\", sentence).strip()\n",
        "    sentence = re.sub('[^A-Za-z]+', ' ', sentence)\n",
        "    sentence = ' '.join(e.lower() for e in sentence.split() if e.lower() not in stopwords)\n",
        "    preprocessed_reviews.append(sentence.strip())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vdicj65KkzR_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(preprocessed_reviews)\n",
        "#preprocessed_reviews[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vg_krlAgk9Jm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#tfidf_vect = TfidfVectorizer()                     #for plain\n",
        "#tfidf_vect = TfidfVectorizer(sublinear_tf = True)  #for sublinear normalisation\n",
        "tfidf_vect = TfidfVectorizer(ngram_range=(2,2),max_features=50000)    #for bigrams\n",
        "#tfidf_vect = TfidfVectorizer(max_df=0.5 )          #for max normalization\n",
        "tfidf_vector = tfidf_vect.fit_transform(preprocessed_reviews[0:5000])\n",
        "tfidf_vector.shape\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hT65qflKlG2X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "explained = []\n",
        "svd = TruncatedSVD(n_components =4000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TuKPSsupSPaG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tfidf_modif = svd.fit_transform(tfidf_vector)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtR1QYdjDhm8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "explained.append(svd.explained_variance_ratio_.sum())\n",
        "print explained\n",
        "tfidf_modif.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_P1GP_iNM2CP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "from sklearn.base import BaseEstimator, ClusterMixin\n",
        "from sklearn.metrics.pairwise import pairwise_kernels\n",
        "from sklearn.utils import check_random_state\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVFRgfV1mezT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class KernelKMeans(BaseEstimator, ClusterMixin):\n",
        "\n",
        "    def __init__(self, n_clusters=3,init='k-means++',max_iter=50, tol=1e-3, random_state=None,\n",
        "                 kernel=\"rbf\", gamma=0.1, degree=3, coef0=1,\n",
        "                 kernel_params=None, verbose=0):\n",
        "        self.n_clusters = n_clusters\n",
        "        self.max_iter = max_iter\n",
        "        self.tol = tol\n",
        "        self.random_state = random_state\n",
        "        self.kernel = kernel\n",
        "        self.init = init\n",
        "        self.gamma = gamma\n",
        "        self.degree = degree\n",
        "        self.coef0 = coef0\n",
        "        self.kernel_params = kernel_params\n",
        "        self.verbose = verbose\n",
        "   \n",
        "    def _pairwise(self):\n",
        "        return self.kernel == \"precomputed\"\n",
        "\n",
        "    def _get_kernel(self, X, Y=None):\n",
        "        if callable(self.kernel):\n",
        "            params = self.kernel_params or {}\n",
        "        else:\n",
        "            params = {\"gamma\": self.gamma,\n",
        "                      \"degree\": self.degree,\n",
        "                      \"coef0\": self.coef0}\n",
        "        return pairwise_kernels(X, Y, metric=self.kernel,\n",
        "                                filter_params=True, **params)\n",
        "\n",
        "    def fit(self, X, y=None, sample_weight=None):\n",
        "        n_samples = X.shape[0]\n",
        "\n",
        "        K = self._get_kernel(X)\n",
        "\n",
        "        sw = sample_weight if sample_weight else np.ones(n_samples)\n",
        "        self.sample_weight_ = sw\n",
        "\n",
        "        rs = check_random_state(self.random_state)\n",
        "        self.labels_ = rs.randint(self.n_clusters, size=n_samples)\n",
        "\n",
        "        dist = np.zeros((n_samples, self.n_clusters))\n",
        "        self.within_distances_ = np.zeros(self.n_clusters)\n",
        "\n",
        "        for it in xrange(self.max_iter):\n",
        "            dist.fill(0)\n",
        "            self._compute_dist(K, dist, self.within_distances_,\n",
        "                               update_within=True)\n",
        "            labels_old = self.labels_\n",
        "            self.labels_ = dist.argmin(axis=1)\n",
        "\n",
        "            # Compute the number of samples whose cluster did not change \n",
        "            # since last iteration.\n",
        "            n_same = np.sum((self.labels_ - labels_old) == 0)\n",
        "            if 1 - float(n_same) / n_samples < self.tol:\n",
        "                if self.verbose:\n",
        "                    print \"Converged at iteration\", it + 1\n",
        "                break\n",
        "\n",
        "        self.X_fit_ = X\n",
        "\n",
        "        return self\n",
        "\n",
        "    def _compute_dist(self, K, dist, within_distances, update_within):\n",
        "        \"\"\"Compute a n_samples x n_clusters distance matrix using the \n",
        "        kernel trick.\"\"\"\n",
        "        sw = self.sample_weight_\n",
        "\n",
        "        for j in xrange(self.n_clusters):\n",
        "            mask = self.labels_ == j\n",
        "\n",
        "            if np.sum(mask) == 0:\n",
        "                raise ValueError(\"Empty cluster found, try smaller n_cluster.\")\n",
        "\n",
        "            denom = sw[mask].sum()\n",
        "            denomsq = denom * denom\n",
        "\n",
        "            if update_within:\n",
        "                KK = K[mask][:, mask]  # K[mask, mask] does not work.\n",
        "                dist_j = np.sum(np.outer(sw[mask], sw[mask]) * KK / denomsq)\n",
        "                within_distances[j] = dist_j\n",
        "                dist[:, j] += dist_j\n",
        "            else:\n",
        "                dist[:, j] += within_distances[j]\n",
        "\n",
        "            dist[:, j] -= 2 * np.sum(sw[mask] * K[:, mask], axis=1) / denom\n",
        "\n",
        "    def predict(self, X):\n",
        "        K = self._get_kernel(X, self.X_fit_)\n",
        "        n_samples = X.shape[0]\n",
        "        dist = np.zeros((n_samples, self.n_clusters))\n",
        "        self._compute_dist(K, dist, self.within_distances_,\n",
        "                           update_within=False)\n",
        "        return dist.argmin(axis=1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lyzt7nMG-eZZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "score= []\n",
        "gamma = [0.01,0.1,1,10,100]\n",
        "for g in gamma :\n",
        "  kernelkmeans = KernelKMeans(init='k-means++', n_clusters=20, random_state =2,gamma = g,max_iter = 100)\n",
        "  X = kernelkmeans.fit(tfidf_modif)\n",
        "  labels = X.labels_\n",
        "  score.append(silhouette_score(tfidf_modif, labels,metric='euclidean' ))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWSWLl5GGw3C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XibohCNaGry8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "kernelkmeans = KernelKMeans(init='k-means++', n_clusters=20, random_state =2,gamma = 0.01)\n",
        "X = kernelkmeans.fit(tfidf_modif)\n",
        "labels = X.labels_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_New9Ndn0XI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset.target[0:5000]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7K4sB4AYG45Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uQHF_IFNG67d",
        "colab": {}
      },
      "source": [
        "print  metrics.adjusted_rand_score(labels, dataset.target[0:5000]);\n",
        "print metrics.adjusted_mutual_info_score(labels, dataset.target[0:5000]);\n",
        "print metrics.normalized_mutual_info_score(labels, dataset.target[0:5000]);\n",
        "print metrics.homogeneity_score(labels, dataset.target[0:5000]);\n",
        "print metrics.completeness_score (labels, dataset.target[0:5000]);\n",
        "print metrics.v_measure_score(labels, dataset.target[0:5000]);\n",
        "print metrics.fowlkes_mallows_score(labels, dataset.target[0:5000]);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxHhyXKkXOYW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.mixture import GaussianMixture\n",
        "sklearn_pca = PCA()\n",
        "Y = sklearn_pca.fit_transform(tfidf_modif)\n",
        "gmm = GaussianMixture(n_components=20, covariance_type='full').fit(Y)\n",
        "gmm_predict = gmm.predict(Y)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iiBmMFKBcfU7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print np.unique(gmm_predict)\n",
        "gmm_predict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMFY_jzjd0Qi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print  metrics.adjusted_rand_score(gmm_predict, dataset.target[0:5000]);\n",
        "print metrics.adjusted_mutual_info_score(gmm_predict, dataset.target[0:5000]);\n",
        "print metrics.normalized_mutual_info_score(gmm_predict, dataset.target[0:5000]);\n",
        "print metrics.homogeneity_score(gmm_predict, dataset.target[0:5000]);\n",
        "print metrics.completeness_score (gmm_predict, dataset.target[0:5000]);\n",
        "print metrics.v_measure_score(gmm_predict, dataset.target[0:5000]);\n",
        "print metrics.fowlkes_mallows_score(gmm_predict, dataset.target[0:5000]);"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}